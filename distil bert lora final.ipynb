{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e42d9bc-880d-4f89-96db-0d47e9df3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c619f20e-3615-463c-be9d-e618358649c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e23c87a6-b5bb-45e4-afff-50fd525a4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig,get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55faac4e-d49c-4c41-b957-89d28720d872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "759c8ba0-6c65-453f-87d9-75df7b92c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cdd6484-90ce-48eb-b984-768ba419f4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa82034b-f32c-478e-879a-2a2d038dea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.rename(columns={'useful':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "667c2ac8-5409-403d-a2b1-cd36d08df208",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59e2d472-cbf5-442e-9d1f-4d72357d0022",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[:,'label'] = dataset['label'].apply(lambda x:1 if x>=3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc94bb58-7c8e-4d8d-8a5c-bdeeb2710ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('cleaned_lora.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "968bdb03-5ab0-48f0-923d-a98056b73ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c3b4526-b61d-4126-9ace-991c26f10770",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "74d4d256-8d8e-4989-880b-e2e3a6e152cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "365d118f-caec-46c3-be4b-84a19767e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "082bb142-e053-48db-816f-2863a8b95d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5efac8714ae2435b91752717ae69831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76352aabe6c84271a6f2bbd93a303017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'],truncation=True, padding='max_length')\n",
    "\n",
    "dataset = dataset.map(tokenize,batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc827b48-e59f-4b6e-a605-f5b02dca6afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# loading base model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f245c-66a6-4ff8-bb34-0aca5f95cfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2adb5e07-6a7e-4530-b431-ac307bb79bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lora config\n",
    "lora_config = LoraConfig(\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    r=8,\n",
    "    lora_alpha = 16,\n",
    "    target_modules=['q_lin','v_lin'], # works for DistilBERT\n",
    "    lora_dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db04f357-605e-439f-b405-fa81d79b5431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model,lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7efac7f-0ab2-478c-83ff-6f902c9a9407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98d102e1-6f7e-4c5a-87cb-5490065eeadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "training_args = TrainingArguments(output_dir='./distilbert-lora-output',\n",
    "                                  per_device_train_batch_size = 2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  num_train_epochs=1,\n",
    "                                  eval_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "39ba6c47-af8e-4d42-b65c-f2a726d4d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model = model,args = training_args,train_dataset=dataset['train'], eval_dataset=dataset['test'],processing_class=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "63cfcd6f-c965-4258-a15c-759199671423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 35:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.614586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=0.5611928367614746, metrics={'train_runtime': 2151.3201, 'train_samples_per_second': 0.744, 'train_steps_per_second': 0.372, 'total_flos': 215583050956800.0, 'train_loss': 0.5611928367614746, 'epoch': 1.0})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b1eff74c-fa26-470c-86ff-0746857f88fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./distilbert-lora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca8e1b4-5ef5-493d-9e3d-ee4a1069eb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ae420bb-97e0-4b22-b27b-a3c35a5e6349",
   "metadata": {},
   "source": [
    "# evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9819d62f-f1de-481f-83ef-914d3203553d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee0d9f71-c25e-42a7-9deb-9790b1bb2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = 'distilbert-base-uncased'\n",
    "lora_model_path = './distilbert-lora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "836db5f6-94aa-418d-8a75-f9d8f50df743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(lora_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c4bbaad0-ed32-4399-aa81-f737ab2efd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mathe\\AppData\\Roaming\\Python\\Python312\\site-packages\\peft\\tuners\\tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PeftModel.from_pretrained(base_model,lora_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7a7adebc-972f-4bcb-afae-954cc259c09c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertForSequenceClassification(\n",
       "      (distilbert): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x TransformerBlock(\n",
       "              (attention): DistilBertSdpaAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (activation): GELUActivation()\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pre_classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9366fc-e90a-4dc7-bdb9-8adf7b221e66",
   "metadata": {},
   "source": [
    "# Making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0f45d136-ce66-44b4-8312-68383ba5671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b31982d7-b9e8-451c-a061-1fe646552fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'the food is good!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "defd46e3-a1a8-4aa5-a1bb-672408ac6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text,return_tensors='pt', padding = 'max_length',max_length=128,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "edb29446-075a-4451-a678-3056bd5ee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits,dim =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2bf8af67-ea0b-4100-9a95-96cde62e9677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b4e24-9493-4e61-b1ca-b5582a071980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
